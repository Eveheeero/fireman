# PSRAW/PSRAD/PSRAQ

Shift Packed Data Right Arithmetic

Shifts the bits in the individual data elements (words, doublewords or quadwords) in the destination operand (first operand) to the right by the number of bits specified in the count operand (second operand).
As the bits in the data elements are shifted right, the empty high-order bits are filled with the initial value of the sign bit of the data element.
If the value specified by the count operand is greater than 15 (for words), 31 (for doublewords), or 63 (for quadwords), each destination data element is filled with the initial value of the sign bit of the element.
(Figure4-18 gives an example of shifting words in a 64-bit operand.)Pre-ShiftX0X3X2X1DESTShift Rightwith SignExtensionPost-Shift>>>>>>>>X0 X3  COUNTX2  COUNTX1  COUNT COUNTDESTFigure 4-18.
 PSRAW and PSRAD Instruction Operation Using a 64-bit OperandNote that only the first 64-bits of a 128-bit count operand are checked to compute the count.
If the second source operand is a memory address, 128 bits are loaded.The (V)PSRAW instruction shifts each of the words in the destination operand to the right by the number of bits specified in the count operand, and the (V)PSRAD instruction shifts each of the doublewords in the destination operand.In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the form of REX.R permits this instruction to access additional registers (XMM8-XMM15).Legacy SSE instructions 64-bit operand: The destination operand is an MMX technology register; the count operand can be either an MMX technology register or an 64-bit memory location.
128-bit Legacy SSE version: The destination and first source operands are XMM registers.
Bits (MAXVL-1:128) of the corresponding YMM destination register remain unchanged.
The count operand can be either an XMM register or a 128-bit memory location or an 8-bit immediate.
If the count operand is a memory address, 128 bits are loaded but the upper 64 bits are ignored.VEX.128 encoded version: The destination and first source operands are XMM registers.
Bits (MAXVL-1:128) of the destination YMM register are zeroed.
The count operand can be either an XMM register or a 128-bit memory loca-tion or an 8-bit immediate.
If the count operand is a memory address, 128 bits are loaded but the upper 64 bits are ignored.VEX.256 encoded version: The destination operand is a YMM register.
The source operand is a YMM register or a memory location.
The count operand can come either from an XMM register or a memory location or an 8-bit EVEX encoded versions: The destination operand is a ZMM register updated according to the writemask.
The count operand is either an 8-bit immediate (the immediate count version) or an 8-bit value from an XMM register or a memory location (the variable count version).
For the immediate count version, the source operand (the second operand) can be a ZMM register, a 512-bit memory location or a 512-bit vector broadcasted from a 32/64-bit memory location.
For the variable count version, the first source operand (the second operand) is a ZMM register, the second source operand (the third operand, 8-bit variable count) can be an XMM register or a memory location.Note: In VEX/EVEX encoded versions of shifts with an immediate count, vvvv of VEX/EVEX encode the destination register, and VEX.B/EVEX.B + ModRM.r/m encodes the source register.Note: For shifts with an immediate count (VEX.128.66.0F 71-73 /4, EVEX.128.66.0F 71-73 /4), VEX.vvvv/EVEX.vvvv encodes the destination register.

## Flags affected

- None.

## Exceptions

- Numeric Exceptions
  > None.
- Other Exceptions
  >  - 
  > VEX-encoded instructions:
  - - - Syntax with RM/RVM operand encoding (A/C in the op
  > erand encoding table), see Table2-21, "Type 4 Class 
  > Exception Conditions."
  - - - Syntax with MI/VMI operand encoding (B/D in the op
  > erand encoding table), see Table2-24, "Type 7 Class 
  > Exception Conditions."
  >  - 
  > EVEX-encoded VPSRAW (E in the operand encoding table), see Exceptions Type E4NF.nb in Table2-50, "Type 
  > E4NF Class Exception Conditions."
  >  - 
  > EVEX-encoded VPSRAD/Q:
  - - - Syntax with Mem128 tuple type (G in the operand
  > encoding table), see Exceptions Type E4NF.nb in 
  > Table2-50, "Type E4NF Class Exception Conditions."
  - - - Syntax with Full tuple type (F in the operand enco

## Operation

```C
PSRAW (With 64-bit Operand)IF (COUNT > 15)THEN COUNT := 16;FI;>> COUNT);DEST[15:0] := SignExtend(DEST[15:0] (* Repeat shift operation for 2nd and 3rd words *)>> COUNT);DEST[63:48] := SignExtend(DEST[63:48] PSRAD (with 64-bit operand)IF (COUNT > 31)THEN COUNT := 32;FI;>> COUNT);DEST[31:0] := SignExtend(DEST[31:0] >>DEST[63:32] := SignExtend(DEST[63:32]  COUNT);ARITHMETIC_RIGHT_SHIFT_DWORDS1(SRC, COUNT_SRC)COUNT := COUNT_SRC[63:0];IF (COUNT > 31)THENDEST[31:0] := SignBitELSEDEST[31:0] := SignExtend(SRC[31:0] >> COUNT);FI;ARITHMETIC_RIGHT_SHIFT_QWORDS1(SRC, COUNT_SRC)COUNT := COUNT_SRC[63:0];IF (COUNT > 63)THENDEST[63:0] := SignBitELSEDEST[63:0] := SignExtend(SRC[63:0] >> COUNT);FI;ARITHMETIC_RIGHT_SHIFT_WORDS_256b(SRC, COUNT_SRC)COUNT := COUNT_SRC[63:0];IF (COUNT > 15)THENCOUNT := 16;FI;DEST[15:0] := SignExtend(SRC[15:0] >> COUNT);ARITHMETIC_RIGHT_SHIFT_DWORDS_256b(SRC, COUNT_SRC)COUNT := COUNT_SRC[63:0];IF (COUNT > 31)THENCOUNT := 32;FI;DEST[31:0] := SignExtend(SRC[31:0] >> COUNT);(* Repeat shift operation for 2nd through 7th words *)DEST[255:224] := SignExtend(SRC[255:224] >> COUNT);ARITHMETIC_RIGHT_SHIFT_QWORDS(SRC, COUNT_SRC, VL) ; VL: 128b, 256b or 512bCOUNT := COUNT_SRC[63:0];IF (COUNT > 63)THENCOUNT := 64;FI;DEST[63:0] := SignExtend(SRC[63:0] >> COUNT);(* Repeat shift operation for 2nd through 7th words *)DEST[VL-1:VL-64] := SignExtend(SRC[VL-1:VL-64] >> COUNT);ARITHMETIC_RIGHT_SHIFT_WORDS(SRC, COUNT_SRC)COUNT := COUNT_SRC[63:0];IF (COUNT > 15)THENCOUNT := 16;FI;DEST[15:0] := SignExtend(SRC[15:0] >> COUNT);(* Repeat shift operation for 2nd through 7th words *)DEST[127:112] := SignExtend(SRC[127:112] >> COUNT);ARITHMETIC_RIGHT_SHIFT_DWORDS(SRC, COUNT_SRC)COUNT := COUNT_SRC[63:0];IF (COUNT > 31)THENCOUNT := 32;FI;DEST[31:0] := SignExtend(SRC[31:0] >> COUNT);(* Repeat shift operation for 2nd through 3rd words *)DEST[127:96] := SignExtend(SRC[127:96] >> COUNT);VPSRAW (EVEX versions, xmm/m128)(KL, VL) = (8, 128), (16, 256), (32, 512)IF VL = 128TMP_DEST[127:0] := ARITHMETIC_RIGHT_SHIFT_WORDS_128b(SRC1[127:0], SRC2)FI;IF VL = 256TMP_DEST[255:0] := ARITHMETIC_RIGHT_SHIFT_WORDS_256b(SRC1[255:0], SRC2)FI;IF VL = 512TMP_DEST[255:0] := ARITHMETIC_RIGHT_SHIFT_WORDS_256b(SRC1[255:0], SRC2)TMP_DEST[511:256] := ARITHMETIC_RIGHT_SHIFT_WORDS_256b(SRC1[511:256], SRC2)FI;FOR j := 0 TO KL-1i := j * 16ELSE IF *merging-masking*; merging-maskingTHEN *DEST[i+15:i] remains unchanged*ELSE *zeroing-masking*; zeroing-masking DEST[i+15:i] = 0FIFI;ENDFORDEST[MAXVL-1:VL] := 0VPSRAW (EVEX Versions, imm8)(KL, VL) = (8, 128), (16, 256), (32, 512)IF VL = 128TMP_DEST[127:0] := ARITHMETIC_RIGHT_SHIFT_WORDS_128b(SRC1[127:0], imm8)FI;IF VL = 256TMP_DEST[255:0] := ARITHMETIC_RIGHT_SHIFT_WORDS_256b(SRC1[255:0], imm8)FI;IF VL = 512TMP_DEST[255:0] := ARITHMETIC_RIGHT_SHIFT_WORDS_256b(SRC1[255:0], imm8)TMP_DEST[511:256] := ARITHMETIC_RIGHT_SHIFT_WORDS_256b(SRC1[511:256], imm8)FI;FOR j := 0 TO KL-1i := j * 16IF k1[j] OR *no writemask*THEN DEST[i+15:i] := TMP_DEST[i+15:i]ELSE IF *merging-masking*; merging-maskingTHEN *DEST[i+15:i] remains unchanged*ELSE *zeroing-masking*; zeroing-masking DEST[i+15:i] = 0FIFI;ENDFORDEST[MAXVL-1:VL] := 0VPSRAW (ymm, ymm, xmm/m128) - VEXDEST[255:0] := ARITHMETIC_RIGHT_SHIFT_WORDS_256b(SRC1, SRC2)DEST[MAXVL-1:256] := 0VPSRAW (ymm, imm8) - VEXDEST[255:0] := ARITHMETIC_RIGHT_SHIFT_WORDS_256b(SRC1, imm8)DEST[MAXVL-1:256] := 0VPSRAW (xmm, xmm, xmm/m128) - VEXDEST[127:0] := ARITHMETIC_RIGHT_SHIFT_WORDS(SRC1, SRC2)DEST[MAXVL-1:128] := 0VPSRAW (xmm, imm8) - VEXDEST[127:0] := ARITHMETIC_RIPSRAW (xmm, xmm, xmm/m128)DEST[127:0] := ARITHMETIC_RIGHT_SHIFT_WORDS(DEST, SRC)DEST[MAXVL-1:128] (Unmodified)PSRAW (xmm, imm8)DEST[127:0] := ARITHMETIC_RIGHT_SHIFT_WORDS(DEST, imm8)DEST[MAXVL-1:128] (Unmodified)VPSRAD (EVEX Versions, imm8)(KL, VL) = (4, 128), (8, 256), (16, 512)FOR j := 0 TO KL-1i := j * 32IF k1[j] OR *no writemask* THENIF (EVEX.b = 1) AND (SRC1 *is memory*)THEN DEST[i+31:i] := ARITHMETIC_RIGHT_SHIFT_DWORDS1(SRC1[31:0], imm8)ELSE DEST[i+31:i] := ARITHMETIC_RIGHT_SHIFT_DWORDS1(SRC1[i+31:i], imm8)FI;ELSE IF *merging-masking*; merging-maskingTHEN *DEST[i+31:i] remains unchanged*ELSE *zeroing-masking*; zeroing-masking DEST[i+31:i] := 0FIFI;ENDFORDEST[MAXVL-1:VL] := 0VPSRAD (EVEX Versions, xmm/m128)(KL, VL) = (4, 128), (8, 256), (16, 512)IF VL = 128TMP_DEST[127:0] := ARITHMETIC_RIGHT_SHIFT_DWORDS_128b(SRC1[127:0], SRC2)FI;IF VL = 256TMP_DEST[255:0] := ARITHMETIC_RIGHT_SHIFT_DWORDS_256b(SRC1[255:0], SRC2)FI;IF VL = 512TMP_DEST[255:0] := ARITHMETIC_RIGHT_SHIFT_DWORDS_256b(SRC1[255:0], SRC2)TMP_DEST[511:256] := ARITHMETIC_RIGHT_SHIFT_DWORDS_256b(SRC1[511:256], SRC2)FI;FOR j := 0 TO KL-1i := j * 32IF k1[j] OR *no writemask*THEN DEST[i+31:i] := TMP_DEST[i+31:i]ELSE IF *merging-masking*; merging-maskingTHEN *DEST[i+31:i] remains unchanged*ELSE *zeroing-masking*; zeroing-masking DEST[i+31:i] := 0FIFI;VPSRAD (ymm, ymm, xmm/m128) - VEXDEST[255:0] := ARITHMETIC_RIGHT_SHIFT_DWORDS_256b(SRC1, SRC2)DEST[MAXVL-1:256] := 0VPSRAD (ymm, imm8) - VEXDEST[255:0] := ARITHMETIC_RIGHT_SHIFT_DWORDS_256b(SRC1, imm8)DEST[MAXVL-1:256] := 0VPSRAD (xmm, xmm, xmm/m128) - VEXDEST[127:0] := ARITHMETIC_RIGHT_SHIFT_DWORDS(SRC1, SRC2)DEST[MAXVL-1:128] := 0VPSRAD (xmm, imm8) - VEXDEST[127:0] := ARITHMETIC_RIGHT_SHIFT_DWORDS(SRC1, imm8)DEST[MAXVL-1:128] := 0PSRAD (xmm, xmm, xmm/m128)DEST[127:0] := ARITHMETIC_RIGHT_SHIFT_DWORDS(DEST, SRC)DEST[MAXVL-1:128] (Unmodified)PSRAD (xmm, imm8)DEST[127:0] := ARITHMETIC_RIGHT_SHIFT_DWORDS(DEST, imm8)DEST[MAXVL-1:128] (Unmodified)VPSRAQ (EVEX Versions, imm8)(KL, VL) = (2, 128), (4, 256), (8, 512)FOR j := 0 TO KL-1i := j * 64IF k1[j] OR *no writemask* THENIF (EVEX.b = 1) AND (SRC1 *is memory*)THEN DEST[i+63:i] := ARITHMETIC_RIGHT_SHIFT_QWORDS1(SRC1[63:0], imm8)ELSE DEST[i+63:i] := ARITHMETIC_RIGHT_SHIFT_QWORDS1(SRC1[i+63:i], imm8)FI;ELSE IF *merging-masking*; merging-maskingTHEN *DEST[i+63:i] remains unchanged*ELSE *zeroing-masking*; zeroing-masking DEST[i+63:i] := 0FIFI;ENDFORDEST[MAXVL-1:VL] := 0VPSRAQ (EVEX Versions, xmm/m128)(KL, VL) = (2, 128), (4, 256), (8, 512)TMP_DEST[VL-1:0] := ARITHMETIC_RIGHT_SHIFT_QWORDS(SRC1[VL-1:0], SRC2, VL)FOR j := 0 TO 7i := j * 64IF k1[j] OR *no writemask*THEN DEST[i+63:i] := TMP_DEST[i+63:i]ELSE ELSE *zeroing-masking*; zeroing-masking DEST[i+63:i] := 0FIFI;ENDFORDEST[MAXVL-1:VL] := 0Intel C/C++ Compiler Intrinsic EquivalentsVPSRAD __m512i _mm512_srai_epi32(__m512i a, unsigned int imm);VPSRAD __m512i _mm512_mask_srai_epi32(__m512i s, __mmask16 k, __m512i a, unsigned int imm);VPSRAD __m512i _mm512_maskz_srai_epi32( __mmask16 k, __m512i a, unsigned int imm);VPSRAD __m256i _mm256_mask_srai_epi32(__m256i s, __mmask8 k, __m256i a, unsigned int imm);VPSRAD __m256i _mm256_maskz_srai_epi32( __mmask8 k, __m256i a, unsigned int imm);VPSRAD __m128i _mm_mask_srai_epi32(__m128i s, __mmask8 k, __m128i a, unsigned int imm);VPSRAD __m128i _mm_maskz_srai_epi32( __mmask8 k, __m128i a, unsigned int imm);VPSRAD __m512i _mm512_sra_epi32(__m512i a, __m128i cnt);VPSRAD __m512i _mm512_mask_sra_epi32(__m512i s, __mmask16 k, __m512i a, __m128i cnt);VPSRAD __m512i _mm512_maskz_sra_epi32( __mmask16 k, __m512i a, __m128i cnt);VPSRAD __m256i _mm256_mask_sra_epi32(__m256i s, __mmask8 k, __m256i a, __m128i cnt);VPSRAD __m256i _mm256_maskz_sra_epi32( __mmask8 k, __m256i a, __m128i cnt);VPSRAD __m128i _mm_mask_sra_epi32(__m128i s, __mmask8 k, __m128i a, __m128i cnt);VPSRAD __m128i _mm_maskz_sra_epi32( __mmask8 k, __m128i a, __m128i cnt);VPSRAQ __m512i _mm512_srai_epi64(__m512i a, unsigned int imm);VPSRAQ __m512i _mm512_mask_srai_epi64(__m512i s, __mmask8 k, __m512i a, unsigned int imm)VPSRAQ __m512i _mm512_maskz_srai_epi64( __mmask8 k, __m512i a, unsigned int imm)VPSRAQ __m256i _mm256_mask_srai_epi64(__m256i s, __mmask8 k, __m256i a, unsigned int imm);VPSRAQ __m256i _mm256_maskz_srai_epi64( __mmask8 k, __m256i a, unsigned int imm);VPSRAQ __m128i _mm_mask_srai_epi64(__m128i s, __mmask8 k, __m128i a, unsigned int imm);VPSRAQ __m128i _mm_maskz_srai_epi64( __mmask8 k, __m128i a, unsigned int imm);VPSRAQ __m512i _mm512_sra_epi64(__m512i a, __m128i cnt);VPSRAQ __m512i _mm512_mask_sra_epi64(__m512i s, __mmask8 k, __m512i a, __m128i cnt)VPSRAQ __m512i _mm512_maskz_sra_epi64( __mmask8 k, __m512i a, __m128i cnt)VPSRAQ __m256i _mm256_mask_sra_epi64(__m256i s, __mmask8 k, __m256i a, __m128i cnt);VPSRAQ __m256i _mm256_maskz_sra_epi64( __mmask8 k, __m256i a, __m128i cnt);VPSRAQ __m128i _mm_mask_sra_epi64(__m128i s, __mmask8 k, __m128i a, __m128i cnt);VPSRAQ __m128i _mm_maskz_sra_epi64( __mmask8 k, __m128i a, __m128i cnt);VPSRAW __m512i _mm512_srai_epi16(__m512i a, unsigned int imm);VPSRAW __m512i _mm512_mask_srai_epi16(__m512i s, __mmask32 k, __m512i a, unsigned int imm);VPSRAW __m512i _mm512_maskz_srai_epi16( __mmask32 k, __m512i a, unsigned int imm);VPSRAW __m256i _mm256_mask_srai_epi16(__m256i s, __mmask16 k, __m256i a, unsigned int imm);VPSRAW __m256i _mm256_maskz_srai_epi16( __mmask16 k, __m256i a, unsigned int imm);VPSRAW __m128i _mm_mask_srai_epi16(__m128i s, __mmask8 k, __m128i a, unsigned int imm);VPSRAW __m128i _mm_maskz_srai_epi16( __mmask8 k, __m128i a, unsigned int imm);VPSRAW __m512i _mm512_sra_epi16(__m512i a, __m128i cnt);VPSRAW __m512i _mm512_mask_sra_epi16(__m512i s, __mmask16 k, __m512i a, __m128i cnt);VPSRAW __m512i _mm512_maskz_sra_epi16( __mmask16 k, __m512i a, __m128i cnt);VPSRAW __m256i _mm256_mask_sra_epi16(__m256i s, __mmask8 k, __m256i a, __m128i cnt);VPSRAW __m256i _mm256_maskz_sra_epi16( __mmask8 k, __m256i a, __m128i cnt);VPSRAW __m128i _mm_mask_sra_epi16(__m128i s, __mmask8 k, __m128i a, __m128i cnt);VPSRAW __m128i _mm_maskz_sra_epi16( __mmask8 k, __m128i a, __m128i cnt);PSRAW __m64 _mm_srai_pi16 (__m64 m, int count)(V)PSRAW __m128i _mm_sra_epi16(__m128i m, __m128i count)VPSRAW __m256i _mm256_srai_epi16 (__m256i m, int count)VPSRAW __m256i _mm256_sra_epi16 (__m256i m, __m128i count)PSRAD __m64 _mm_srai_pi32 (__m64 m, int count)PSRAD __m64 _mm_sra_pi32 (__m64 m, __m64 count)(V)PSRAD __m128i _mm_srai_epi32 (__m128i m, int count)(V)PSRAD __m128i _mm_sra_epi32 (__m128i m, __m128i count)VPSRAD __m256i _mm256_srai_epi32 (__m256i m, int count)VPSRAD __m256i _mm256_sra_epi32 (__m256i m, __m128i count)
```
