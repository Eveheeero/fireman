# VBROADCAST

Load with Broadcast Floating-Point Data

VBROADCASTSD/VBROADCASTSS/VBROADCASTF128 load floating-point values as one tuple from the source operand (second operand) in memory and broadcast to all elements of the destination operand (first operand).
VEX256-encoded versions: The destination operand is a YMM register.
The source operand is either a 32-bit, 64-bit, or 128-bit memory location.
Register source encodings are reserved and will #UD.
Bits (MAXVL-1:256) of the desti-nation register are zeroed.EVEX-encoded versions: The destination operand is a ZMM/YMM/XMM register and updated according to the writemask k1.
The source operand is either a 32-bit, 64-bit memory location or the low doubleword/quadword element of an XMM register.
VBROADCASTF32X2/VBROADCASTF32X4/VBROADCASTF64X2/VBROADCASTF32X8/VBROADCASTF64X4 load floating-point values as tuples from the source operand (the second operand) in memory or register and broadcast to all elements of the destination operand (the first operand).
The destination operand is a YMM/ZMM register updated according to the writemask k1.
The source operand is either a register or 64-bit/128-bit/256-bit memory location.VBROADCASTSD and VBROADCASTF128,F32x4 and F64x2 are only supported as 256-bit and 512-bit wide versions and up.
VBROADCASTSS is supported in 128-bit, 256-bit and 512-bit wide versions.
F32x8 and F64x4 are only supported as 512-bit wide versions.VBROADCASTF32X2/VBROADCASTF32X4/VBROADCASTF32X8 have 32-bit granularity.
VBROADCASTF64X2 and VBROADCASTF64X4 have 64-bit granularity.
Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise instructions will #UD.If VBROADCASTSD or VBROADCASTF128 is encoded with VEX0X0X0X0X0X0X0X0X0m32DESTFigure 5-1.
 VBROADCASTSS Operation (VEX.256 encoded version)X0X0X0X00X0000m32DESTFigure 5-2.
 VBROADCASTSS Operation (VEX.128-bit version)m64X0DESTX0X0X0X0Figure 5-3.
 VBROADCASTSD Operation (VEX.256-bit version)m128X0DESTX0m256X0DESTX0X0Figure 5-5.
 VBROADCASTF64X4 Operation (512-bit version with writemask all 1s)

## Operation

```C
VBROADCASTSS (128-bit Version VEX and Legacy)temp := SRC[31:0]DEST[31:0] := tempDEST[63:32] := tempDEST[95:64] := tempDEST[127:96] := tempDEST[MAXVL-1:128] := 0VBROADCASTSS (VEX.256 Encoded Version)temp := SRC[31:0]DEST[31:0] := tempDEST[63:32] := tempDEST[95:64] := tempDEST[127:96] := tempDEST[159:128] := tempDEST[191:160] := tempDEST[223:192] := tempDEST[255:224] := tempDEST[MAXVL-1:256] := 0VBROADCASTSS (EVEX Encoded Versions)(KL, VL) (4, 128), (8, 256),= (16, 512)FOR j := 0 TO KL-1i := j * 32IF k1[j] OR *no writemask*THEN DEST[i+31:i] := SRC[31:0]ELSE IF *merging-masking*; merging-maskingTHEN *DEST[i+31:i] remains unchanged*ELSE ; zeroing-maskingDEST[i+31:i] := 0FIFI;VBROADCASTSD (VEX.256 Encoded Version)temp := SRC[63:0]DEST[63:0] := tempDEST[127:64] := tempDEST[191:128] := tempDEST[255:192] := tempDEST[MAXVL-1:256] := 0VBROADCASTSD (EVEX Encoded Versions)(KL, VL) = (4, 256), (8, 512)FOR j := 0 TO KL-1i := j * 64IF k1[j] OR *no writemask*THEN DEST[i+63:i] := SRC[63:0]ELSE IF *merging-masking*; merging-maskingTHEN *DEST[i+63:i] remains unchanged*ELSE ; zeroing-maskingDEST[i+63:i] := 0FIFI;ENDFORDEST[MAXVL-1:VL] := 0VBROADCASTF32x2 (EVEX Encoded Versions)(KL, VL) = (8, 256), (16, 512)FOR j := 0 TO KL-1i := j * 32n := (j mod 2) * 32IF k1[j] OR *no writemask*THEN DEST[i+31:i] := SRC[n+31:n]ELSE IF *merging-masking*; merging-maskingTHEN *DEST[i+31:i] remains unchanged*ELSE ; zeroing-maskingDEST[i+31:i] := 0FIFI;ENDFORDEST[MAXVL-1:VL] := 0VBROADCASTF128 (VEX.256 Encoded Version)temp := SRC[127:0]DEST[127:0] := tempVBROADCASTF32X4 (EVEX Encoded Versions)(KL, VL) = (8, 256), (16, 512)FOR j := 0 TO KL-1i := j* 32n := (j modulo 4) * 32IF k1[j] OR *no writemask*THEN DEST[i+31:i] := SRC[n+31:n]ELSE IF *merging-masking*; merging-maskingTHEN *DEST[i+31:i] remains unchanged*ELSE ; zeroing-maskingDEST[i+31:i] := 0FIFI;ENDFORDEST[MAXVL-1:VL] := 0VBROADCASTF64X2 (EVEX Encoded Versions)(KL, VL) = (4, 256), (8, 512)FOR j := 0 TO KL-1i := j * 64n := (j modulo 2) * 64IF k1[j] OR *no writemask*THEN DEST[i+63:i] := SRC[n+63:n]ELSE IF *merging-masking*; merging-maskingTHEN *DEST[i+63:i] remains unchanged*ELSE ; zeroing-maskingDEST[i+63:i] = 0FIFI;ENDFOR;VBROADCASTF32X8 (EVEX.U1.512 Encoded Version)FOR j := 0 TO 15i := j * 32n := (j modulo 8) * 32IF k1[j] OR *no writemask*THEN DEST[i+31:i] := SRC[n+31:n]ELSE IF *merging-masking*; merging-maskingTHEN *DEST[i+31:i] remains unchanged*ELSE ; zeroing-maskingDEST[i+31:i] := 0FIFI;VBROADCASTF64X4 (EVEX.512 Encoded Version)FOR j := 0 TO 7i := j * 64n := (j modulo 4) * 64IF k1[j] OR *no writemask*THEN DEST[i+63:i] := SRC[n+63:n]ELSE IF *merging-masking*; merging-maskingTHEN *DEST[i+63:i] remains unchanged*ELSE ; zeroing-maskingDEST[i+63:i] := 0FIFI;ENDFORDEST[MAXVL-1:VL] := 0Intel C/C++ Compiler Intrinsic EquivalentVBROADCASTF32x2 __m512 _mm512_broadcast_f32x2( __m128 a);VBROADCASTF32x2 __m512 _mm512_mask_broadcast_f32x2(__m512 s, __mmask16 k, __m128 a);VBROADCASTF32x2 __m512 _mm512_maskz_broadcast_f32x2( __mmask16 k, __m128 a);VBROADCASTF32x2 __m256 _mm256_broadcast_f32x2( __m128 a);VBROADCASTF32x2 __m256 _mm256_mask_broadcast_f32x2(__m256 s, __mmask8 k, __m128 a);VBROADCASTF32x2 __m256 _mm256_maskz_broadcast_f32x2( __mmask8 k, __m128 a);VBROADCASTF32x4 __m512 _mm512_broadcast_f32x4( __m128 a);VBROADCASTF32x4 __m512 _mm512_mask_broadcast_f32x4(__m512 s, __mmask16 k, __m128 a);VBROADCASTF32x4 __m512 _mm512_maskz_broadcast_f32x4( __mmask16 k, __m128 a);VBROADCASTF32x4 __m256 _mm256_broadcast_f32x4( __m128 a);VBROADCASTF32x4 __m256 _mm256_mask_broadcast_f32x4(__m256 s, __mmask8 k, __m128 a);VBROADCASTF32x4 __m256 _mm256_maskz_broadcast_f32x4( __mmask8 k, __m128 a);VBROADCASTF32x8 __m512 _mm512_broadcast_f32x8( __m256 a);VBROADCASTF32x8 __m512 _mm512_mask_broadcast_f32x8(__m512 s, __mmask16 k, __m256 a);VBROADCASTF32x8 __m512 _mm512_maskz_broadcast_f32x8( __mmask16 k, __m256 a);VBROADCASTF64x2 __m512d _mm512_broadcast_f64x2( __m128d a);VBROADCASTF64x2 __m512d _mm512_mask_broadcast_f64x2(__m512d s, __mmask8 k, __m128d a);VBROADCASTF64x2 __m512d _mm512_maskz_broadcast_f64x2( __mmask8 k, __m128d a);VBROADCASTF64x2 __m256d _mm256_broadcast_f64x2( __m128d a);VBROADCASTF64x2 __m256d _mm256_mask_broadcast_f64x2(__m256d s, __mmask8 k, __m128d a);VBROADCASTF64x2 __m256d _mm256_maskz_broadcast_f64x2( __mmask8 k, __m128d a);VBROADCASTF64x4 __m512d _mm512_broadcast_f64x4( __m256d a);VBROADCASTF64x4 __m512d _mm512_mask_broadcast_f64x4(__m512d s, __mmask8 k, __m256d a);VBROADCASTF64x4 __m512d _mm512_maskz_broadcast_f64x4( __mmask8 k, __m256d a);VBROADCASTSD __m512d _mm512_broadcastsd_pd( __m128d a); VBROADCASTSD __m512d _mm512_mask_broadcastsd_pd(__m512d s, __mmask8 k, __m128d a); VBROADCASTSD __m512d _mm512_maskz_broadcastsd_pd(__mmask8 k, __m128d a); VBROADCASTSD __m256d _mm256_broadcastsd_pd(__m128d a);VBROADCASTSD __m256d _mm256_mask_broadcastsd_pd(__m256d s, __mmask8 k, __m128d a);VBROADCASTSD __m256d _mm256_maskz_broadcastsd_pd( __mmask8 k, __m128d a);VBROADCASTSD __m256d _mm256_broadcast_sd(double *a);VBROADCASTSS __m512 _mm512_broadcastss_ps( __m128 a); VBROADCASTSS __m512 _mm512_mask_broadcastss_ps(__m512 s, __mmask16 k, __m128 a); VBROADCASTSS __m512 _mm512_maskz_broadcastss_ps( __mmask16 k, __m128 a); VBROADCASTSS __m256 _mm256_broadcastss_ps(__m128 a);VBROADCASTSS __m256 _mm256_mask_broadcastss_ps(__m256 s, __mmask8 k, __m128 a);VBROADCASTSS __m128 _mm_broadcastss_ps(__m128 a);VBROADCASTSS __m128 _mm_mask_broadcastss_ps(__m128 s, __mmask8 k, __m128 a);VBROADCASTSS __m128 _mm_maskz_broadcastss_ps( __mmask8 k, __m128 a);VBROADCASTSS __m128 _mm_broadcast_ss(float *a);VBROADCASTSS __m256 _mm256_broadcast_ss(float *a);VBROADCASTF128 __m256 _mm256_broadcast_ps(__m128 * a);VBROADCASTF128 __m256d _mm256_broadcast_pd(__m128d * a);ExceptionsVEX-encoded instructions, see Table2-23, "Type 6 Class Exception Conditions."EVEX-encoded instructions, see Table2-53, "Type E6 Class Exception Conditions."Additionally:#UDIf VEX.L = 0 for VBROADCASTSD or VBROADCASTF128.If EVEX.L'L = 0 for VBROADCASTSD/VBROADCASTF32X2/VBROADCASTF32X4/VBROAD-
```
